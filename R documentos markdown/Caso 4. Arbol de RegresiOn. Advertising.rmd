---
title: "Caso 4. Arbol de Regresión. Datos Advertising"
author: "Rubén Pizarro Gurrola"
date: "17/3/2022"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: yes
bibliography: references.bib
---

# Objetivo

Construir y evaluar un modelo de árbol de regresión para realizar predicciones y comparar resultados con el modelo de regresión lineal múltiple

# Descripción

-   Se cargan las librerías necesarias

-   Se cargan los datos Se exploran los datos

-   Se crear los datos de entrenamiento y validación 70% y 30% respectivamente

Las métricas a valorar serán:

-   Que los coeficientes sean estadísticamente significativos por encima del 95%.

-   *R Squared Ajustado* el modelo se acepta si sobrepasa en el 80%

-   *rmse* comparado con otro modelo mismos datos se acepta o se establece que un modelo es mejor que otro.

-   Comparaciones con el modelo de regresión lineak múltiple

# Marco teórico

Los algoritmos de aprendizaje basados en árbol se consideran uno de los mejores y más utilizados métodos de aprendizaje supervisado. Potencian modelos predictivos con alta precisión, estabilidad y facilidad de interpretación.

Los árboles de clasificación y regresión son métodos que proporcionan modelos que satisfacen objetivos tanto predictivos como explicativos.

Dos de los puntos fuertes de este método son, por un lado, la sencilla representación gráfica mediante árboles y, por otro, el formato compacto de las reglas de lenguaje natural.

Se distinguen dos casos en que estas técnicas de modelado deben utilizarse: - Utilizar árboles de clasificación para explicar y predecir la pertenencia de los objetos (observaciones, individuos) a una clase, sobre la base de variables explicativas cuantitativas y cualitativas.

Utilizar un árbol de regresión para crear un modelo explicativo y predictivo para una variable cuantitativa dependiente basada en variables explicativas independientes cuantitativas y cualitativas.

# Desarrollo

## Cargar librerías

```{r message=FALSE, warning=FALSE}

library(readr) # Para importar datos
library(dplyr) # Para filtrar   
library(knitr) # Para datos tabulares
library(ggplot2) # Para visualizar
library(plotly)
library(caret)  # Para particionar
library(Metrics) # Para determinar rmse

library(rpart) # Para árbol
library(rpart.plot) # Para árbol
```

## Cargar datos

```{r}
datos <- read.csv("https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/Advertising.csv")
```

## Explorando los datos

```{r}
summary(datos)
str(datos)
```

Son 200 registros tres variables independientes y una variable dependiente.

La variable dependiente o variable objetivo es *Sales* que deberá estar en función de la inversión que se hace en *TV*, *Radio* o *Newspaper*.

## Limpiar datos

Quitar la variable x que no es de interés

```{r}
datos <- datos %>%
  select (TV, Radio, Newspaper, Sales)
```

### head(datos)

```{r}
kable(head(datos, 20), caption = "Primeros 20 registros")
```

### tail(datos)

```{r}
kable(tail(datos, 20), caption = "Últimos 20 registros")
```

## Datos de entrenamiento y validación

### Datos de entrenamiento

```{r}
n <- nrow(datos)

# Modificar la semilla estableciendo como parámetro los útimos cuatro dígitos de su no de control. 
# Ej. set.seed(0732), o set.seed(1023)
# set.seed(2022) 
set.seed(2022)

```

De manera aleatoria se construyen los datos de entrenamiento y los datos de validación.

En la variable *entrena* se generan los registros que van a ser los datos de entrenamiento, de tal forma que los datos de validación serán los que no sena de entrenamiento [-*entrena*].

```{r}

entrena <- createDataPartition(y = datos$Sales, p = 0.70, list = FALSE, times = 1)

# Datos entrenamiento
datos.entrenamiento <- datos[entrena, ]  # [renglones, columna]

# Datos validación
datos.validacion <- datos[-entrena, ]
```

#### head()

```{r}
kable(head(datos.entrenamiento, 20), caption = "Datos de Entrenamiento. Primeros 20 registros")

```

#### tail()

```{r}
kable(tail(datos.entrenamiento, 20), caption = "Datos de entrenamiento ültimos 20 registros")
```

### Datos de validación

Los datos de validación deben ser diferentes a los datos den entrenamiento.

#### head()

```{r}
kable(head(datos.validacion, 20), caption = "Datos de Validación Primeros 20 registros")

```

#### tail()

```{r}
kable(tail(datos.validacion, 20), caption = "Datos de validació últimos 20 registros")
```

## Construir el modelo

Se construye el modelo con la función *rpart*

```{r}
modelo_ar <- rpart(data = datos.entrenamiento,formula = Sales ~ TV + Radio + Newspaper )
modelo_ar

```

### resumen del modelo

```{r}
summary(modelo_ar)
```

### Representar visualmente el árbol de regresión

```{r}
rpart.plot(modelo_ar)

```

## Predecir valores con datos de validación

```{r}
predicciones <- predict(object = modelo_ar, newdata = datos.validacion)


```

Construir un *data frame* para comparar y luego evaluar

```{r}
comparaciones <- data.frame(datos.validacion, predicciones)
comparaciones
```

## *rmse* Root Mean Stándard Error (*Root-mean-square deviation*),

Este valor normalmente se compara contra otro modelo y el que esté mas cerca de cero es mejor.

La raiz del Error Cuadrático Medio (*rmse*) es una métrica que dice qué tan lejos están los valores predichos de los valores observados o reales en un análisis de regresión, en promedio. Se calcula como:

$$
rmse = \sqrt{\frac{\sum(predicho_i - real_i)^{2}}{n}}
$$

*RMSE* es una forma útil de ver qué tan bien un modelo de regresión puede ajustarse a un conjunto de datos.

Cuanto mayor sea el *rmse*, mayor será la diferencia entre los valores predichos y reales, lo que significa que peor se ajusta un modelo de regresión a los datos. Por el contrario, cuanto más pequeño sea el *rmse*, mejor podrá un modelo ajustar los datos.

Se compara este valor de *rmse* con respecto al modelo de regresión múltiple que fue de 1.590948 y este modelo de árbol de regresión se obtiene un valor de *rmse* de 1.455681, por lo tanto bajo este criterio el modelo de árbol de regresión es mejor comparado con el modelo de regresión múltiple.

```{r}
rmse <- rmse(actual = comparaciones$Sales, predicted = comparaciones$predicciones)
rmse
```

## Graficar predicciones contra valores reales

```{r}
ggplot(data = comparaciones) +
  geom_line(aes(x = 1:nrow(comparaciones), y = Sales), col='blue') +
  geom_line(aes(x = 1:nrow(comparaciones), y = predicciones), col='yellow') +
  ggtitle(label="Valores reales vs predichos Adverstising", subtitle = "Arbol de Regresión") 
  
  
```

## Predicciones con datos nuevos

```{r}
TV <- c(140, 160)
Radio <- c(60, 40)
Newspaper <- c(80, 90) 

nuevos <- data.frame(TV, Radio, Newspaper)  
nuevos

Y.predicciones <- predict(object = modelo_ar, newdata = nuevos)
Y.predicciones
```

# Interpretación 

Comentarios pesonal acerca del caso

# Bibliografía

Pendiente
